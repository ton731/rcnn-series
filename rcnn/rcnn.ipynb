{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/codex/implementing-r-cnn-object-detection-on-voc2012-with-pytorch-b05d3c623afe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import tarfile\n",
    "from pathlib import Path\n",
    "import os\n",
    "import random\n",
    "import xml.etree.ElementTree as ET\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VOCDataset:\n",
    "    def __init__(self):\n",
    "        self.root = Path(\"data\")\n",
    "        self.root.mkdir(parents=True, exist_ok=True)\n",
    "        self.train_dir = None\n",
    "        self.test_dir = None\n",
    "        self.train_data_link = None\n",
    "        self.test_data_link = None\n",
    "\n",
    "\n",
    "    def common_init(self):\n",
    "        # init for shared subclasses\n",
    "        self.label_type = ['none','aeroplane',\"Bicycle\",'bird',\"Boat\",\"Bottle\",\"Bus\",\"Car\",\"Cat\",\"Chair\",'cow',\"Diningtable\",\"Dog\",\"Horse\",\"Motorbike\",'person', \"Pottedplant\",'sheep',\"Sofa\",\"Train\",\"TVmonitor\"]\n",
    "        self.convert_id = ['background','Aeroplane',\"Bicycle\",'Bird',\"Boat\",\"Bottle\",\"Bus\",\"Car\",\"Cat\",\"Chair\",'Cow',\"Dining table\",\"Dog\",\"Horse\",\"Motorbike\",'Person', \"Potted plant\",'Sheep',\"Sofa\",\"Train\",\"TV/monitor\"]\n",
    "        self.convert_labels = {}\n",
    "        for i, x in enumerate(self.label_type):\n",
    "            self.convert_labels[x.lower()] = i\n",
    "\n",
    "        self.num_classes = len(self.label_type)     # 20 class + 1 background\n",
    "    \n",
    "\n",
    "    def download_dataset(self, validation_size=5000):\n",
    "        # download voc train dataset\n",
    "        if os.path.exists(self.root / \"voctrain.tar\"):\n",
    "            print(\"[*] Dataset already exists!\")\n",
    "        else:\n",
    "            print(\"[*] Downloading dataset...\")\n",
    "            print(self.train_data_link)\n",
    "            urllib.request.urlretrieve(self.train_data_link, self.root / \"voctrain.tar\")\n",
    "\n",
    "        if os.path.exists(self.root / \"VOCtrain\"):\n",
    "            print(\"[*] Dataset is already extracted!\")\n",
    "        else:\n",
    "            print(\"[*] Extracting dataset...\")\n",
    "            tar = tarfile.open(self.root / \"voctrain.tar\")\n",
    "            tar.extractall(self.root / \"VOCtrain\")\n",
    "            tar.close()\n",
    "\n",
    "        # download test dataset\n",
    "        if os.path.exists(self.root / \"VOCtest\"):\n",
    "            print(\"[*] Test dataset already exist!\")\n",
    "        else:\n",
    "            if self.test_data_link is None:\n",
    "                # move 5k images to validation set\n",
    "                print(\"[*] Moving validation data...\")\n",
    "                test_annotation_dir = self.test_dir / \"Annotations\"\n",
    "                test_img_dir = self.test_dir / \"JPEGImages\"\n",
    "                test_annotation_dir.mkdir(parents=True, exist_ok=True)\n",
    "                test_img_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "                random.seed(731)\n",
    "                val_img_paths = random.sample(sorted(os.listdir(self.train_dir / \"JPEGImages\")), validation_size)\n",
    "\n",
    "                for path in val_img_paths:\n",
    "                    img_name = str(path).split(\"/\")[-1].split(\".\")[0]\n",
    "                    # move image\n",
    "                    os.rename(self.train_dir / \"JPEGImages\" / f\"{img_name}.jpg\", test_img_dir / f\"{img_name}.jpg\")\n",
    "                    # move annotation\n",
    "                    os.rename(self.train_dir / \"Annotations\" / f\"{img_name}.xml\", test_annotation_dir / f\"{img_name}.xml\")\n",
    "            else:\n",
    "                # load from val data\n",
    "                print(\"[*] Downloading validation dataset...\")\n",
    "                urllib.request.urlretrieve(self.test_data_link, \"voctset.tar\")\n",
    "\n",
    "                print(\"[*] Extracting validation dataset...\")\n",
    "                tar = tarfile.open(\"voctest.tar\", \"r:\")\n",
    "                tar.extractall(\"/content/VOCtest\")\n",
    "                tar.close()\n",
    "                # os.remove(\"/content/voctset.tar\")\n",
    "\n",
    "\n",
    "    def read_xml(self, xml_path):\n",
    "        object_list = []\n",
    "\n",
    "        tree = ET.parse(open(xml_path, 'r'))\n",
    "        root = tree.getroot()\n",
    "\n",
    "        objects = root.findall(\"object\")\n",
    "        for _object in objects:\n",
    "            name = _object.find(\"name\").text\n",
    "            bndbox = _object.find(\"bndbox\")\n",
    "            xmin = int(bndbox.find(\"xmin\").text)\n",
    "            ymin = int(bndbox.find(\"ymin\").text)\n",
    "            xmax = int(bndbox.find(\"xmax\").text)\n",
    "            ymax = int(bndbox.find(\"ymax\").text)\n",
    "            class_name = _object.find(\"name\").text\n",
    "            object_list.append({'x1':xmin, 'x2':xmax, 'y1':ymin, 'y2':ymax, 'class':self.convert_labels[class_name]})\n",
    "        \n",
    "        return object_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VOC2007(VOCDataset):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.train_dir = self.root / 'VOCtrain/VOCdevkit/VOC2007'\n",
    "        self.test_dir = self.root / 'VOCtest/VOCdevkit/VOC2007'\n",
    "        self.train_data_link = 'http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar'\n",
    "        self.test_data_link = 'http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar'\n",
    "        self.common_init()  #mandatory\n",
    "    \n",
    "class VOC2012(VOCDataset):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.train_dir = self.root / 'VOCtrain/VOCdevkit/VOC2012'\n",
    "        self.test_dir = self.root / 'VOCtest/VOCdevkit/VOC2012'\n",
    "        # original site goes down frequently, so we use a link to the clone alternatively\n",
    "        # self.train_data_link = 'http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar' \n",
    "        self.train_data_link = 'http://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar'\n",
    "        self.test_data_link = None\n",
    "        self.common_init()  #mandatory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Dataset already exists!\n",
      "[*] Dataset is already extracted!\n",
      "[*] Test dataset already exist!\n"
     ]
    }
   ],
   "source": [
    "voc_dataset = VOC2012()\n",
    "voc_dataset.download_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data num: 12125\n",
      "valid data num: 5000\n"
     ]
    }
   ],
   "source": [
    "train_data_num = len(os.listdir(voc_dataset.train_dir / \"Annotations\"))\n",
    "valid_data_num = len(os.listdir(voc_dataset.test_dir / \"Annotations\"))\n",
    "print(\"train data num:\", train_data_num)\n",
    "print(\"valid data num:\", valid_data_num)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_img(img_path):\n",
    "    print(\"plotting:\", img_path)\n",
    "    img_bgr = cv2.imread(img_path)\n",
    "    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "    print(\"img shape:\", img_rgb.shape)\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def plot_bounding_box(img_path):\n",
    "    # img\n",
    "    print(\"plotting:\", img_path)\n",
    "    img_bgr = cv2.imread(img_path)\n",
    "    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    xml_path = img_path.replace(\"JPEGImages\", \"Annotations\").replace(\".jpg\", \".xml\")\n",
    "    tree = ET.parse(open(xml_path, 'r'))\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    # print image shape\n",
    "    w, h = root.find(\"size\").find(\"width\").text, root.find(\"size\").find(\"height\").text\n",
    "    print(\"width, height:\", w, h)\n",
    "\n",
    "    # bounding box settings\n",
    "    box_img = img_bgr.copy()\n",
    "    bbox_color = (0, 69, 255)    # bgr\n",
    "    bbox_thickness = 2\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    font_scale = 0.5\n",
    "    font_color = bbox_color\n",
    "    line_type = 1\n",
    "\n",
    "    # plot box\n",
    "    objects = root.findall(\"object\")\n",
    "    for _object in objects:\n",
    "        name = _object.find(\"name\").text\n",
    "        bndbox = _object.find(\"bndbox\")\n",
    "        xmin = int(bndbox.find(\"xmin\").text)\n",
    "        ymin = int(bndbox.find(\"ymin\").text)\n",
    "        xmax = int(bndbox.find(\"xmax\").text)\n",
    "        ymax = int(bndbox.find(\"ymax\").text)\n",
    "        class_name = _object.find('name').text\n",
    "\n",
    "        cv2.rectangle(box_img, (xmin, ymin), (xmax, ymax), bbox_color, bbox_thickness)\n",
    "        cv2.putText(box_img, class_name, (xmin, ymin-5), font, font_scale, font_color, line_type)\n",
    "\n",
    "    box_img_rgb = cv2.cvtColor(box_img, cv2.COLOR_BGR2RGB)\n",
    "    result = np.hstack((img_rgb, box_img_rgb))\n",
    "    # plt.imshow(result)\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.show()\n",
    "    plt.imshow(box_img_rgb)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name = random.choice(os.listdir(voc_dataset.train_dir / \"JPEGImages\"))\n",
    "img_path = str(voc_dataset.train_dir / \"JPEGImages\" / img_name)\n",
    "plot_bounding_box(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rcnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6efa59ba0514c88bea28add7efbea712f86beb100fe6589447027613f52b616e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
